{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd78a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# A sample training component that trains a simple scikit-learn decision tree model.\n",
    "# This implementation works in File mode and makes no assumptions about the input file names.\n",
    "# Input is specified as CSV with a data point in each row and the labels in the first column.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "\n",
    "# These are the paths to where SageMaker mounts interesting things in your container.\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = prefix + 'input/data'\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "param_path = os.path.join(prefix, 'input/config/hyperparameters.json')\n",
    "\n",
    "# This algorithm has a single channel of input data called 'training'. Since we run in\n",
    "# File mode, the input files are copied to the directory specified here.\n",
    "channel_name='training'\n",
    "training_path = os.path.join(input_path, channel_name)\n",
    "\n",
    "def get_start_end_re(data,word):\n",
    "    if re.search(r'\\b'+re.escape(word)+r'\\b', data):\n",
    "        return data.find(word),data.find(word)+len(word)-1\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def createDateSpacyFormat(text_data,label,entityName):\n",
    "    spacyFormat = []\n",
    "    for count in tqdm(range(len(text_data))):\n",
    "        tupList = []\n",
    "        entDict = {}\n",
    "#         tupList.append(text_data[count])\n",
    "        if get_start_end_re(text_data[count],label[count]) == False:\n",
    "            continue\n",
    "        else:\n",
    "            start_index, end_index = get_start_end_re(text_data[count],label[count])\n",
    "            temp_list = list(('start_index', 'end_index', 'Word'))\n",
    "            temp_list[0] = start_index\n",
    "            temp_list[1] = end_index\n",
    "            temp_list[2] = entityName\n",
    "            entList = []\n",
    "            entList.append(tuple(temp_list))\n",
    "            entDict['entities'] = entList\n",
    "            tupList.append(text_data[count])\n",
    "            tupList.append(entDict)\n",
    "            spacyFormat.append(tuple(tupList))\n",
    "    return spacyFormat\n",
    "def create_training(TRAIN_DATA):\n",
    "    \n",
    "    db = DocBin() # create a DocBin object\n",
    "\n",
    "    for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
    "        doc = nlp.make_doc(text) # create doc object from text\n",
    "        ents = []\n",
    "#         print(text)\n",
    "#         print(annot[])\n",
    "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "            print(\"*********** Starting*****************\")\n",
    "            print(span)\n",
    "            print(start)\n",
    "            print(end)\n",
    "            print(label)\n",
    "            print(\"*********** Ending*****************\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents # label the text with the ents\n",
    "        db.add(doc)\n",
    "    return (db)\n",
    "\n",
    "\n",
    "# The function to execute the training.\n",
    "def train():\n",
    "    print('Starting the training.')\n",
    "    try:\n",
    "        # Read in any hyperparameters that the user passed with the training job\n",
    "        with open(param_path, 'r') as tc:\n",
    "            trainingParams = json.load(tc)\n",
    "            \n",
    "            \n",
    "        print(\"trainning Parameeter:------\",trainingParams)\n",
    "\n",
    "        # Take the set of files and read them all into a single pandas dataframe\n",
    "        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]\n",
    "        if len(input_files) == 0:\n",
    "            raise ValueError(('There are no files in {}.\\n' +\n",
    "                              'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                              'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                              'does not have permission to access the data.').format(training_path, channel_name))\n",
    "        dataframe = [ pd.read_excel(file) for file in input_files if file.endswith(\".xlsx\")][0]\n",
    "        \n",
    "        data1 = list(dataframe['PageText'])\n",
    "        data2 = list(dataframe['compDate'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data1,data2,test_size=0.2)\n",
    "\n",
    "        nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data1,data2,test_size=0.2)\n",
    "        spacyformat = createDateSpacyFormat(X_train,y_train,\"IncepDate\")\n",
    "        X_tr, X_te= train_test_split(spacyformat,test_size=0.2)\n",
    "\n",
    "        new_training_data = create_training(X_tr[:100])\n",
    "        new_training_data.to_disk(\"train.spacy\")\n",
    "\n",
    "        new_testing_data = create_training(X_te[:50])\n",
    "        new_testing_data.to_disk(\"dev.spacy\")\n",
    "\n",
    "\n",
    "        os.system('! python -m spacy init fill-config base_config.cfg config.cfg')\n",
    "        os.system('python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy')\n",
    "        \n",
    "        nlp = spacy.load('output/model-best')\n",
    "\n",
    "        \n",
    "        \n",
    "        # save the model\n",
    "        with open(os.path.join(model_path, 'spacy_ner.pkl'), 'wb') as out:\n",
    "            pickle.dump(nlp, out)\n",
    "        print('Training complete.')\n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print('Exception during training: ' + str(e) + '\\n' + trc, file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec6d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad956dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec0210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3ade8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d9239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a9834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
